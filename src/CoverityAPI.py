#from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.firefox.service import Service
from selenium.webdriver import ActionChains
from seleniumwire import webdriver
from seleniumwire.webdriver import Firefox
from seleniumwire.request import Request, Response
from helpers.InterceptorTimeout import InterceptorTimeout
from selenium.common.exceptions import TimeoutException
from seleniumwire.utils import decode
import os
import json
import logging
import subprocess
from threading import Condition
from enum import Enum
from coverage import LOGGER_NAME
import re
import shutil
import time
from logging import FileHandler
import csv


logger = logging.getLogger(LOGGER_NAME)

#TODO: remove logs generated by Selenium

class RecentSnapshotStates(Enum):
    NOT_STARTED = 0
    STARTED_BUT_NOT_FOUND = 1
    FOUND = 2

class DefectsStates(Enum):
    NOT_STARTED = 0
    STARTED_BUT_NOT_FOUND = 1
    FOUND = 2


def dummy_request_interceptor(request : Request):
    return

def dummy_response_interceptor(request : Request, response : Response):
    return

def recent_snapshot_response_interceptor(request : Request, response : Response):

    coverityAPI : CoverityAPI = CoverityAPI(configs=None, defects_download_path=None)

    if coverityAPI.recent_snapshot_state in [RecentSnapshotStates.NOT_STARTED, RecentSnapshotStates.FOUND]:
        logger.debug(f"RECENT SNAPSHOT: Ignoring {request.url} for recent snapshot since state is {coverityAPI.recent_snapshot_state.name}")
        return

    logger.debug(f"RECENT SNAPSHOT: Investigating {request.url}")
    
    # this is used in the rest of the time to poll for the submited build as a snapshot, knowing the snapshot view id and project view id
    if request.url == coverityAPI.snapshots_table_url:
        logger.debug(f"RECENT SNAPSHOT: Found snapshot table at {request.url}")
        with coverityAPI.interceptor_condition:
            
            # https://stackoverflow.com/questions/67306915/selenium-wire-response-object-way-to-get-response-body-as-string-rather-than-b
            snapshot_payload = json.loads(decode(response.body, response.headers.get('Content-Encoding', 'identity')))['resultSet']['results']

            if snapshot_payload == []:
                coverityAPI.cached_recent_snapshot = None
            else:
                coverityAPI.cached_recent_snapshot = snapshot_payload[0]

            logger.debug(f"Found most recent snapshot {coverityAPI.cached_recent_snapshot}")

            coverityAPI.recent_snapshot_state = RecentSnapshotStates.FOUND

            coverityAPI.interceptor_condition.notify()

    return

def defects_response_interceptor(request : Request, response : Response):

    coverityAPI : CoverityAPI = CoverityAPI(configs=None, defects_download_path=None)

    logger.debug(f"RECENT DEFECTS: Investigating {request.url}")

    if coverityAPI.defects_state in [DefectsStates.NOT_STARTED, DefectsStates.FOUND]:
        logger.debug(f"DEFECTS: Ignoring {request.url} for recent defects since status is {coverityAPI.defects_state.name}")
        return
    
    logger.debug(f"RECENT DEFECTS: Investigating {request.url}")
    current_defect_view_match = re.match(r"https://scan9\.scan\.coverity\.com/reports/table\.json\?projectId=(\d+)&viewId=(\d+)", request.url)

    if current_defect_view_match:
        
        coverityAPI.current_defects_view_id = current_defect_view_match.group(2)

        logger.debug(f"RECENT DEFECTS: Found copy of the defects view with id {coverityAPI.current_defects_view_id} at {request.url}")

        with coverityAPI.interceptor_condition:

            coverityAPI.cached_last_defect_results = json.loads(decode(response.body, response.headers.get('Content-Encoding', 'identity')))['resultSet']['results']

            coverityAPI.defects_state = DefectsStates.FOUND

            coverityAPI.interceptor_condition.notify()
    
    return

class CoverityAPI(object):

    user_email : str
    user_pass : str
    browser : Firefox
    scraper_wait : int
    project_overview_url : str
    project_id : int
    snapshots_url : str
    snapshots_table_url : str
    snapshots_view_id : int
    current_defects_view_id : int
    recent_snapshot_state : RecentSnapshotStates
    defects_state : DefectsStates
    interceptor_condition : Condition
    cached_last_defect_results : list[dict]
    cached_recent_snapshot : dict
    interceptor_timeout : int
    is_auth : bool
    log_file : str
    upload_token : str
    user_email : str
    project_name : str
    unknown_snapshot : bool
    snapshot_polling_seconds : int

    def __new__(cls, configs : dict | None, defects_download_path : str) -> None:
        if not hasattr(cls, 'instance') and configs != None:
            
            cls.instance : CoverityAPI = super(CoverityAPI, cls).__new__(cls)

            cls.instance.log_file = configs['logfile']
            cls.instance.upload_token = configs['coverityAPI']['uploadToken']
            cls.instance.user_email = configs["coverityAPI"]['userEmail']
            cls.instance.project_name = configs['coverityAPI']['projectName']

            cls.instance.unknown_snapshot = True
            cls.instance.snapshot_polling_seconds = configs["coverityAPI"]['snapshotPollingSeconds']
            cls.instance.defects_download_path =defects_download_path
            cls.instance.options = Options()
            cls.instance.options.set_preference("browser.download.dir", defects_download_path)
            cls.instance.options.set_preference("browser.download.manager.showWhenStarting", True)
            cls.instance.options.set_preference("browser.helperApps.neverAsk.saveToDisk", "application/octet-stream")
            cls.instance.options.set_preference("browser.download.folderList", 2)
            cls.instance.options.binary_location = configs["coverityAPI"]["firefoxPath"]
            gecko_service = Service(configs["coverityAPI"]["geckoPath"])
            cls.instance.browser = webdriver.Firefox(options=cls.instance.options, service=gecko_service)

            cls.instance.interceptor_condition = Condition()

            cls.instance.browser.request_interceptor = dummy_request_interceptor

            cls.instance.recent_snapshot_state = RecentSnapshotStates.NOT_STARTED
            cls.instance.defects_state = DefectsStates.NOT_STARTED

            cls.instance.scraper_wait = configs["coverityAPI"]["scraperWaitSeconds"]
            cls.instance.project_overview_url = configs["coverityAPI"]["projectOverviewURL"]

            cls.instance.interceptor_timeout = configs["coverityAPI"]["interceptorTimeoutSeconds"]

            cls.instance.is_auth = False

        return cls.instance
    
    def auth(self):

        browser = self.browser

        browser.switch_to.new_window('tab')

        browser.get(self.project_overview_url)

        try:
            # wait until "View Defects" button can be seen and clicked. This means that we wait until the user MANUALLY logs in and solves the captcha
            WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, "/html/body/div[1]/div[2]/div/div/div[3]/div[1]/p[1]/a")))
        except TimeoutException as te:
            self.is_auth = False
            raise te
        
        self.is_auth = True

        return
    
    def poll_recent_snapshot(self, compilation_tag : str | None) -> bool:

        if not self.is_auth:
            logger.warning("Authenticating before checking the most recent snapshot")
            try:
                self.auth()
            except TimeoutException as te:
                logger.critical("Authentication failed during fetching the most recent snapshot")
                raise te

        browser = self.browser
        
        if compilation_tag != None:
            logger.debug("Start intercepting for snapshot resultSet response")
        else:
            logger.debug("Start searching for snapshots view id and project view id as the first step")
        
        browser.switch_to.new_window('tab')

        coverity_project_name = self.project_overview_url.split("/")[-1].split("?")[0]

        coverity_view_defects_url = f"https://scan.coverity.com/projects/{coverity_project_name}/view_defects"

        browser.get(coverity_view_defects_url)

        logger.info(f"Request GET for {coverity_view_defects_url} for snapshot investigation")

        try:
            more_options = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
            more_options.click()
        except TimeoutException as te:
            logger.critical("Cannot click on more options burger button")
            raise te

        logger.debug("Clicked on more options. Next choose `All in project` snapshots option")
        time.sleep(2)

        try:
            
            all_in_snapshot = WebDriverWait(browser, self.scraper_wait).until(EC.presence_of_element_located((By.XPATH, "/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[9]/div/ul/li[1]/div/a")))

            WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, "/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[9]/div/ul/li[1]/div/a")))
            # this is the first time calling this function so we need to find the snapshot view id and project view id
            if self.unknown_snapshot:
                all_in_snapshot_element = browser.find_element(By.XPATH, "/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[9]/div/ul/li[1]/div/a")

                snapshots_href = all_in_snapshot_element.get_attribute("href")
                
                self.project_id = snapshots_href.split("/")[-1]

                self.snapshots_view_id = snapshots_href.split("/")[-2]

                self.unknown_snapshot = False

                logger.info(f"Snapshot view id is {self.snapshots_view_id} and project view id is {self.project_id}")

                # this url is accessible and will trigger a request to the second one which contains snapshots data
                self.snapshots_url = f"https://scan9.scan.coverity.com/#/project-view/{self.snapshots_view_id}/{self.project_id}"
                self.snapshots_table_url = f"https://scan9.scan.coverity.com/reports/table.json?projectId={self.project_id}&viewId={self.snapshots_view_id}"


                return True

            # init interceptor which will search for snapshot information in the response body
            else:
                self.recent_snapshot_state = RecentSnapshotStates.STARTED_BUT_NOT_FOUND
                browser.response_interceptor = recent_snapshot_response_interceptor

            all_in_snapshot.click()

            logger.debug("Clicked on `All in project` snapshot option")

            time.sleep(2)

        except TimeoutException as te:
            logger.critical("Cannot click on the `All in project` snapshot option")
            raise te
        

        # wait until the interceptor finds the response that contains the snapshot details
        with self.interceptor_condition:
            while self.recent_snapshot_state != RecentSnapshotStates.FOUND:
                self.interceptor_condition.wait(self.interceptor_timeout)

                # timeout inside the interceptor
                if self.recent_snapshot_state != RecentSnapshotStates.FOUND:
                    logger.critical(f"Interceptor timeout. Expected {RecentSnapshotStates.FOUND.name}, got {self.recent_snapshot_state.name}")
                    return False
                
            # reinit the state of the snapshots interceptor maybe for further use
            self.recent_snapshot_state = RecentSnapshotStates.NOT_STARTED

            # stop interceptor so that we do not pollute the log file too much
            self.browser.response_interceptor = dummy_response_interceptor
            logger.debug("RECENT SNAPSHOT: Interceptor stopped")

        if compilation_tag == None:
            logger.debug("Initial polling OK. Finished finding snapshot view id and project view id")
            return True
        
        if self.cached_recent_snapshot['snapshotDescription'] != compilation_tag:
            logger.warning(f"Recent snapshot has compilation tag \"{self.cached_recent_snapshot['snapshotDescription']}\", expected \"{compilation_tag}\". Needs retrying.")

            # the build has not been analyzed yet, we need to wait before retrying to get the most recent snpashot containing the build
            time.sleep(self.snapshot_polling_seconds)
            return False
        else:
            logger.warning(f"Found uploaded snapshot with tag {compilation_tag}")
        

        return True
    
    def init_snapshot_and_project_views(self):
        self.poll_recent_snapshot(None)

    def remove_snapshot_view(self) -> None:

        browser = self.browser

        try:
            views_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
            views_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on burger button in order to add new snapshot view")
            raise te

        logger.debug("Clicked on burger button. Now try to click arrow button of the first snapshot view.")
        time.sleep(2)

        try:
            arrow_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[2]/div/ul/li[1]/div/a/span')))
            arrow_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on arrow button of the first snapshot view.")
            raise te

        logger.debug("Clicked on arrow button. Now click on `Delete...` button")
        time.sleep(2)

        try:
            delete_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="ui-menu-item-remove"]')))
            delete_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Delete...` button")
            raise te
        
        logger.debug("Click on `Delete...` button. Next click on Delete")
        time.sleep(2)

        try:
            delete_ok = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-delete-modal/cim-base-modal/div/div[3]/div/div/button[2]/span')))
            delete_ok.click()
        except TimeoutException as te:
            logger.critical("Cannot click on Delete last button")
            raise te
        
        logger.debug("Clicked on last Delete button. Now click back on burger button to go to the first state before this operation")
        time.sleep(2)

        try:
            views_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
            views_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on burger button in order to go to the start state before this operation")
            raise te

        logger.debug("Delete the snapshot linked to the most added compilation. Great success !")

        return

    def __create_snapshot_view(self, compilation_tag : str) -> None:
        
        browser = self.browser

        try:
            views_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
            views_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on burger button in order to add new snapshot view")
            raise te

        logger.debug("Clicked on burger button. Now try to click arrow button in `Issues: By Snapshot`.")
        time.sleep(2)

        try:
            arrow_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[2]/div/h4/span')))
            arrow_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on arrow button in `Issues: By snapshot`.")
            raise te

        logger.debug("Clicked on arrow button. Now click on `Add New View...` button")
        time.sleep(2)

        try:
            add_new_view_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-sidebar/div[1]/cim-context-menu/div/ul/li[1]/span')))
            add_new_view_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Add new View...` in `Issues: By Snapshot`")
            raise te
        
        logger.debug("Clicked on `Add new View...` in `Issues: By Snapshot`. Now write compilation tag as snapshot name")
        time.sleep(2)

        try:
            add_as_input_element = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="name"]')))
            add_as_input_element.send_keys(compilation_tag)
        except TimeoutException as te:
            logger.critical("Cannot name the snapshot as the compilation tag")
            raise te
        
        logger.debug("Added name of the snapshot as the compialtino tag. Now click on OK button")
        time.sleep(2)

        try:
            ok_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-add-view-modal/cim-base-modal/div/div[3]/div/div/button[2]')))
            ok_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on OK button after naming the snapshot as the compilation tag")
            raise te
        
        logger.debug("Clicked on OK button. Click again on burger button to return to initial web view state.")
        time.sleep(2)

        try:
            views_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
            views_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on burger button in order to return to initial web view state.")
            raise te

        logger.debug("Clicked on burger button. Adding new snapshot based on compiltation tag finished.")


        return

    def fetch_and_cache_recent_defects_1(self, compilation_tag : str) -> None:
        import time

        if not self.is_auth:
            logger.warn("Authenticating before fetching most recent defects...")
            try:
                self.auth()
            except TimeoutException as te:
                logger.critical("Authentication failed during fetching defects in the most recent snapshot")
                raise te
            
        browser = self.browser

        # try to intercept response body which contains all snapshot information
        browser.switch_to.new_window('tab')

        browser.get(self.snapshots_url)
        
        try:
            recent_snapshot_cell = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-project-view/div[1]/div[1]/div[1]/cim-data-table/angular-slickgrid/div/div/div[4]/div[3]/div/div[1]/div[2]')))
            double_click_snapshot_cell = ActionChains(browser).double_click(recent_snapshot_cell).perform()
        except TimeoutException as te:                                                                                    
            logger.critical("Cannot find most recent snapshot cell when fetching defects")
            raise te
        time.sleep(2)

        # Add more columns
        try:
            edit_settings_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="current-selection-settings"]')))
            edit_settings_button.click()
        except TimeoutException as te:
                logger.critical("Cannot find `edit settings` button")
                raise te
        
        logger.debug("Opened settings in order to add additional columns in the snapshot view. Next click on `Save as Copy` button")
        time.sleep(2)

        try:
            save_as_copy_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[2]/div/div/form/ul/li[2]/label')))
            save_as_copy_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Save as Copy` button")
            raise te

        logger.debug("Clicked on `Save as Copy` button. Next click the `Column` button")
        time.sleep(2)

        try:
            column_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[2]/div/div/fieldset/div/ul/li[2]/a/span')))
            column_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Column` button")
            raise te

        logger.debug("Clicked on column button. Next choose `Checker` column")
        time.sleep(2)

        try:
            checker_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-checker"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", checker_column)
            time.sleep(1)
            checker_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Checker` column")
            raise te

        logger.debug("Clicked on `Checker` column. Next choose `CWE` column")
        time.sleep(2)

        try:
            cwe_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-cwe"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", cwe_column)
            time.sleep(1)
            cwe_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `CWE` column")
            raise te
        
        logger.debug("Clicked on `CWE` column. Next choose `Line Number` column")
        time.sleep(2)

        try:
            line_number_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-lineNumber"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", line_number_column)
            time.sleep(1)
            line_number_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Line Number` column")
            raise te
        
        logger.debug("Clicked on `Line Number` column. Next choose `Score` column")
        time.sleep(2)

        try:
            score_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-score"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", score_column)
            time.sleep(1)
            score_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Score` column")
            raise te

        logger.debug("Clicked on `Score` column. Next enter name of the snapshot issue copy")
        time.sleep(2)

        try:
            snapshot_copy_input = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="view-name"]')))
            snapshot_copy_input.clear()
            snapshot_copy_input.send_keys(compilation_tag)
        except TimeoutException as te:
            logger.critical("Cannot input the name of the snapshot issue copy")
            raise te

        logger.debug("Chose a name for the snapshot issue copy. Next click on `OK` button.")
        time.sleep(2)

        try:
            ok_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[3]/div/div/button[2]')))
            ok_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `OK` button to finish adding more columns. Next will try to click burger button.")
            raise te

        logger.debug("Finished adding new columns. Now try to click burger button")
        time.sleep(30)

        try:
            views_button = WebDriverWait(browser, self.scraper_wait).until(EC.visibility_of_element_located((By.XPATH, '//*[@id="views-button"]')))
            views_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on burger button in order to find the most recent snapshot saved with enhanced collumns")
            raise te

        logger.debug("Click on burger button, now go to the most recent snapshot (that was created when selected additional columns) arrow button with more options")
        time.sleep(2)

        try:
            recent_snapshot_more_options = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[2]/div/ul/li[1]/div/a/span')))
            recent_snapshot_more_options.click()
        except TimeoutException as te:
            logger.critical("Cannot click on most recent snapshot more options arrow button")
            raise te

        logger.debug("Clicked on more options arrow button at the most recent snapshot. Now click on export csv option")


        try:
            export_csv = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="ui-menu-item-exportcsv"]')))
            export_csv.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Export CSV` option")
            raise te
    
        logger.debug("Clicked on `Export CSV` option. Now wait for the downloaded defects as csv document to be downloaded")
            
        downloading = True
        download_time = 0

        csv_file_name = compilation_tag.replace(" ", "+") + ".csv"

        download_file_path = None

        while downloading and download_time <= self.scraper_wait:

            time.sleep(1)

            for file_path in os.listdir(self.defects_download_path):
                if file_path == csv_file_name or re.match(r".*\.csv", file_path):
                    downloading = False
                    download_file_path = os.path.join(self.defects_download_path, file_path)
                    break
            
            if downloading:
                download_time += 1

        if download_time > self.scraper_wait:
            logger.critical("Timeout exceeded for downloading defects as csv file")
            raise TimeoutException()
        
        logger.debug(f"Defects downloaded as csv file from {download_file_path}")

        with open(download_file_path, 'r') as f:
            csv_lines = csv.DictReader(f)
            for line in csv_lines:
                self.cached_last_defect_results.append(line)

        logger.debug("Parsed defects from csv and cached them")

        try:
            self.remove_snapshot_view()
        except TimeoutException as te:
            raise te

        return


    def fetch_and_cache_recent_defects(self, compilation_tag : str) -> None:
        
        import time

        if not self.is_auth:
            logger.warn("Authenticating before fetching most recent defects...")
            try:
                self.auth()
            except TimeoutException as te:
                logger.critical("Authentication failed during fetching defects in the most recent snapshot")
                raise te
            
        browser = self.browser

        # try to intercept response body which contains all snapshot information
        browser.switch_to.new_window('tab')

        browser.get(self.snapshots_url)
        
        try:
            recent_snapshot_cell = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/cim-root/cim-shell/div/cim-project-view/div[1]/div[1]/div[1]/cim-data-table/angular-slickgrid/div/div/div[4]/div[3]/div/div[1]/div[2]')))
            double_click_snapshot_cell = ActionChains(browser).double_click(recent_snapshot_cell).perform()
        except TimeoutException as te:
            logger.critical("Cannot find most recent snapshot cell when fetching defects")
            raise te
        time.sleep(2)
        # Add more columns
        try:
            edit_settings_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="current-selection-settings"]')))
            edit_settings_button.click()
        except TimeoutException as te:
                logger.critical("Cannot find `edit settings` button")
                raise te
        
        logger.debug("Opened settings in order to add additional columns in the snapshot view. Next click on `Save as Copy` button")
        time.sleep(2)

        try:
            save_as_copy_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[2]/div/div/form/ul/li[2]/label')))
            save_as_copy_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Save as Copy` button")
            raise te

        logger.debug("Clicked on `Save as Copy` button. Next click no `Column` button")
        time.sleep(2)

        try:
            column_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[2]/div/div/fieldset/div/ul/li[2]/a/span')))
            column_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `Column` button")
            raise te

        logger.debug("Clicked on column button. Next choose `Checker` column")
        time.sleep(2)

        try:
            checker_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-checker"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", checker_column)
            time.sleep(1)
            checker_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Checker` column")
            raise te

        logger.debug("Clicked on `Checker` column. Next choose `CWE` column")
        time.sleep(2)

        try:
            cwe_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-cwe"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", cwe_column)
            time.sleep(1)
            cwe_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `CWE` column")
            raise te
        
        logger.debug("Clicked on `CWE` column. Next choose `Line Number` column")
        time.sleep(2)

        try:
            line_number_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-lineNumber"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", line_number_column)
            time.sleep(1)
            line_number_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Line Number` column")
            raise te
        
        logger.debug("Clicked on `Line Number` column. Next choose `Score` column")
        time.sleep(2)

        try:
            score_column = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="select-score"]')))
            browser.execute_script("arguments[0].scrollIntoView(true);", score_column)
            time.sleep(1)
            score_column.click()
        except TimeoutException as te:
            logger.critical("Cannot choose `Score` column")
            raise te

        logger.debug("Clicked on `Score` column. Next enter name of the snapshot issue copy")
        time.sleep(2)

        try:
            snapshot_copy_input = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="view-name"]')))
            snapshot_copy_input.clear()
            snapshot_copy_input.send_keys(compilation_tag)
        except TimeoutException as te:
            logger.critical("Cannot input the name of the snapshot issue copy")
            raise te

        logger.debug("Chose a name for the snapshot issue copy. Next click on `OK` button to finish and start intercepting the response body for defects")
        time.sleep(2)

        self.defects_state = DefectsStates.STARTED_BUT_NOT_FOUND
        browser.response_interceptor = defects_response_interceptor

        try:
            ok_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '/html/body/simple-modal-holder/simple-modal-wrapper/div/cim-setting-modal/cim-base-modal/div/div[3]/div/div/button[2]')))

            logger.debug("Init defects response interceptor")
            # only after initialising the interceptor, we can click on 'OK'
            ok_button.click()
        except TimeoutException as te:
            logger.critical("Cannot click on `OK` button to finish adding more columns")
            raise te

        logger.debug("Finished adding new columns. Now try to intercept the response ")

        with self.interceptor_condition:
            while self.defects_state != DefectsStates.FOUND:
                self.interceptor_condition.wait(self.interceptor_timeout)

                # timeout inside the interceptor
                if self.defects_state != DefectsStates.FOUND:
                    logger.critical(f"Interceptor timeout. Expected {DefectsStates.FOUND.name}, got {self.defects_state}")
                    raise InterceptorTimeout()
                
            # reinit the state of the defects interceptor maybe for further use
            self.defects_state = DefectsStates.NOT_STARTED
            
        return
    
    def intercept_build(self, compile_cmd : str, coverity_suite_path : str, app_path : str) -> bool:

        logger.debug(f"Started intercepting the build with {coverity_suite_path} for command {compile_cmd} in app {app_path}")

        logs_file_handler : FileHandler = logger.handlers[0]

        os.chdir(app_path)

        if os.path.exists(f"{app_path}/.unikraft"):

            logger.warning("Detected already built app. Removing the .unikraft directory using kraft clean --proper")

            clean_proc = subprocess.Popen(f"kraft clean --proper --log-level debug {app_path}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            out, err = clean_proc.communicate()

            logger.debug(f"Output app kraft cleaning: \n{out.decode()}")

            logger.error(f"Error app kraft cleaning: \n{err.decode()}")

            clean_proc.terminate()

            shutil.rmtree(f"{app_path}/.unikraft")

        cov_build_subprocess = subprocess.Popen(f"{coverity_suite_path} --dir cov-int {compile_cmd}", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        out, err = cov_build_subprocess.communicate()

        cov_build_subprocess.terminate()

        compilation_success_msg = b"C/C++ compilation units (100%) are ready for analysis"

        logger.debug(f"Output build interception: \n{out.decode()}")

        logger.warning(f"Error build interception: \n{err.decode()}")

        if (compilation_success_msg not in out) or (cov_build_subprocess.returncode != 0):
            logger.critical(f"The app has compilation issues. The compilation ration should be 100% in order to you the compilation coverage tool")
            return False

        if b"No files were emitted." in err:
            logger.critical("The app was previously compiled. Remove the .unikraft directory and try again")
            return False
        
        return True


    def submit_build(self, app_path : str, compile_cmd : str, compilation_tag : str) -> bool:

        os.chdir(app_path)
        
        archive_proc = subprocess.Popen(f"tar czvf {app_path}/analysis_input.tgz cov-int", shell=True)

        archive_proc.communicate()

        archive_proc.terminate()

        upload_proc = subprocess.Popen(f'curl --form token="{self.upload_token}" --form email={self.user_email} --form "file=@./analysis_input.tgz" --form version=1 --form description="{compilation_tag}" https://scan.coverity.com/builds?project={self.project_name}', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        out, err = upload_proc.communicate()
        
        upload_proc.terminate()

        logger.warning(err)

        logger.debug(out)
        
        # Coverity limits the number of builds you upload
        quota_msg = b"The build submission quota for this project has been reached."
        
        if quota_msg in out:
            logger.critical("Quota for Coverity submited builds reached. Try again next time")
            return False
        
        os.remove("analysis_input.tgz")

        shutil.rmtree("cov-int")

        logger.debug("Removing archiving for Coverity and intercept results directory")
    
        return True
                    

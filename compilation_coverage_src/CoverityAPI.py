#from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.firefox.service import Service
from selenium.webdriver import ActionChains
from seleniumwire import webdriver
from seleniumwire.webdriver import Firefox
from seleniumwire.request import Request, Response
from seleniumwire.utils import decode
from helpers.InterceptorTimeout import InterceptorTimeout
import os
import json
import logging
import subprocess
import re
from threading import Condition
from enum import Enum


logger = logging.getLogger(__name__)

#TODO: remove logs generated by Selenium

class MetadataStates(Enum):
    NOT_STARTED = 0
    START_OK_FIND_SNAPSHOT = 1
    SNAPSHOT_OK_FIND_DEFECT_VIEW = 2
    DEFECT_OK_STOP = 3

class RecentSnapshotStates(Enum):
    NOT_STARTED = 0
    STARTED_BUT_NOT_FOUND = 1
    FOUND = 2

class DefectsStates(Enum):
    NOT_STARTED = 0
    STARTED_BUT_NOT_FOUND = 1
    FOUND = 2


def dummy_request_interceptor(request : Request):
    return

def recent_snapshot_response_interceptor(request : Request, response : Response):
    coverityAPI = CoverityAPI()

    if coverityAPI.recent_snapshot_state in [RecentSnapshotStates.NOT_STARTED, RecentSnapshotStates.FOUND]:
        logger.debug(f"RECENT SNAPSHOT: Ignoring {request.url} for recent snapshot since state is {coverityAPI.recent_snapshot_state.name}")
        return

    if request.url == coverityAPI.snapshots_table_url:
        with coverityAPI.interceptor_condition:
            coverityAPI.cached_recent_snapshot = json.loads(response.body.decode('utf-8'))['resultSet']['results'][0]

            logger.debug(f"Found most recent snapshot {coverityAPI.cached_recent_snapshot}")

            coverityAPI.recent_snapshot_state = RecentSnapshotStates.FOUND

            coverityAPI.interceptor_condition.notify()

    return

def defects_response_interceptor(request : Request, response : Response):

    coverityAPI = CoverityAPI()

    if coverityAPI.defects_state in [DefectsStates.NOT_STARTED, DefectsStates.FOUND]:
        logger.debug(f"DEFECTS: Ignoring {request.url} for recent defects since status is {coverityAPI.defects_state.name}")
        return
    
    if request.url == coverityAPI.defects_table_url:
        with coverityAPI.interceptor_condition:

            coverityAPI.cached_last_defect_results = json.loads(response.body.decode('utf-8'))['resultSet']['results']

            logger.debug(f"Found last defects {coverityAPI.cached_last_defect_results}")

            coverityAPI.defects_state = DefectsStates.FOUND

            coverityAPI.interceptor_condition.notify()
    
    return


def metadata_response_interceptor(request : Request, response : Response):
    coverityAPI = CoverityAPI()

    if coverityAPI.metadata_state in [MetadataStates.NOT_STARTED, MetadataStates.DEFECT_OK_STOP]:
        logger.debug(f"METADATA: Ignoring {request.url} since browser has interceptor state {coverityAPI.metadata_state.name}")
        return
    
    if coverityAPI.metadata_state == MetadataStates.START_OK_FIND_SNAPSHOT:
        logger.debug(f"Searching for snapshot view id in {request.url}")

        match_proj_snapshot_view = re.search(r"https://scan9\.scan\.coverity\.com/reports/table\.json\?projectId=(\d+)&viewId=(\d+)", request.url)

        if match_proj_snapshot_view:
            
            with coverityAPI.interceptor_condition:

                coverityAPI.project_id = match_proj_snapshot_view.group(1)
                coverityAPI.snapshots_view_id = match_proj_snapshot_view.group(2)
            
                logger.info(f"This current account has snapshot view id {coverityAPI.snapshots_view_id} and project id {coverityAPI.project_id}")

                coverityAPI.snapshots_url = f"https://scan9.scan.coverity.com/#/project-view/{coverityAPI.snapshots_view_id}/{coverityAPI.project_id}"

                coverityAPI.snapshots_table_url = f"https://scan9.scan.coverity.com/reports/table.json\?projectId={coverityAPI.project_id}&viewId={coverityAPI.snapshots_view_id}"

                coverityAPI.metadata_state = MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW

                coverityAPI.interceptor_condition.notify()

            return
    
    if coverityAPI.metadata_state == MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW:
        logger.debug(f"Searching for defect view id in {request.url}")

        match_proj_snapshot = re.search(r"https://scan9\.scan\.coverity\.com/reports/defects\.json\?projectId=(\d+)&snapshotExpression=(\d+)", request.url)

        if match_proj_snapshot:

            with coverityAPI.interceptor_condition:

                project_id_1 = match_proj_snapshot.group(1)

                #TODO check project id

                snapshot_id = match_proj_snapshot.group(2)

                match_defect_view_proj = re.search(r"/reports\.htm#v(\d+)/p(\d+)", json.loads(response.body.decode('utf-8'))['url'])

                coverityAPI.defects_view_id = match_defect_view_proj.group(1)

                project_id_2 = match_proj_snapshot.group(2)

                #TODO check project id 

                coverityAPI.defects_url = f"https://scan9.scan.coverity.com/#/project-view/{coverityAPI.defects_view_id}/{coverityAPI.project_id}"

                coverityAPI.defects_table_url = f"https://scan9.scan.coverity.com/reports/table.json?projectId={coverityAPI.project_id}&viewId={coverityAPI.defects_view_id}"

                logger.debug(f"Found project id {project_id_1} with latest snapshot id {snapshot_id} and project id {project_id_2} with defect view id {coverityAPI.defects_view_id}")

                coverityAPI.metadata_state = MetadataStates.DEFECT_OK_STOP

                coverityAPI.interceptor_condition.notify()

            return
    
    if coverityAPI.metadata_state == MetadataStates.DEFECT_OK_STOP:
        logger.debug(f"Searching for defect results in {request.url}")

        if request.url == coverityAPI.defects_table_url:
            
            with coverityAPI.interceptor_condition:

                coverityAPI.cached_last_defect_results = json.loads(response.body.decode('utf-8'))['resultSet']['results']

                coverityAPI.metadata_state = MetadataStates.DEFECT_OK_STOP

                coverityAPI.interceptor_condition.notify()

    return

class CoverityAPI(object):

    user_email : str
    user_pass : str
    upload_token : str
    browser : Firefox
    scraper_wait : int
    project_overview_url : str
    project_id : int
    snapshots_url : str
    snapshots_table_url : str
    snapshots_view_id : int
    defects_url : str
    defects_table_url : str
    defects_view_id : int
    metadata_state : MetadataStates
    recent_snapshot_state : RecentSnapshotStates
    defects_state : DefectsStates
    interceptor_condition : Condition
    cached_last_defect_results : list[dict]
    cached_recent_snapshot : dict
    interceptor_timeout : int

    def __new__(cls, configs : dict | None) -> None:
        if not hasattr(cls, 'instance'):
            
            cls.instance : CoverityAPI = super(CoverityAPI, cls).__new__(cls)

            cls.instance.interceptor_condition = Condition()

            cls.instance.browser.request_interceptor = dummy_request_interceptor

            cls.instance.metadata_state = MetadataStates.NOT_STARTED
            cls.instance.recent_snapshot_state = RecentSnapshotStates.NOT_STARTED
            cls.instance.defects_state = DefectsStates.NOT_STARTED

            cls.instance.options.binary_location = configs["CoverityAPI"]["firefoxPath"]
            cls.instance.options = Options()
            gecko_service = Service(configs["CoverityAPI"]["geckoPath"])
            cls.instance.browser = webdriver.Firefox(options=cls.instance.options, service=gecko_service)

            cls.instance.scraper_wait = configs["CoverityAPI"]["scraperWaitSeconds"]
            cls.instance.project_overview_url = configs["CoverityAPI"]["projectOverviewURL"]

            cls.instance.interceptor_timeout = configs["CoverityAPI"]["interceptorTimeoutSeconds"]

        return cls.instance

    def fetch_metadata(self) -> list[dict]:

        browser : Firefox = self.browser

        # start interceptor that searches for snapshot view id, project id, etc.
        self.browser.response_interceptor = metadata_response_interceptor

        browser.get(self.project_overview_url)

        logger.debug("Entering the project overview")

        # we set interceptor to start searching for the snapshot view id 
        self.metadata_state = MetadataStates.START_OK_FIND_SNAPSHOT

        view_defects_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, "/html/body/div[1]/div[2]/div/div/div[3]/div[1]/p[1]/a")))
        
        project_summary_window = browser.current_window_handle

        view_defects_button.click()

        WebDriverWait(browser, self.scraper_wait).until(EC.number_of_windows_to_be(2))

        if browser.window_handles[1] != project_summary_window:
            browser.switch_to.window(browser.window_handles[1])
        else:
            browser.switch_to.window(browser.window_handles[0])

        logger.info("Switching to second tab in browser where defects are OK")

        # click the "burger" button in the top left 
        more_options_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, '//*[@id="views-button"]')))
        more_options_button.click()

        # from the popped up menu click "All snapshots"
        all_snapshots_button = WebDriverWait(browser, self.scraper_wait).until(EC.element_to_be_clickable((By.XPATH, "/html/body/cim-root/cim-shell/div/cim-sidebar/nav/div/div[9]/div/ul/li[1]/div/a")))

        # click it. Now traffic will also include the snapshots view id
        all_snapshots_button.click()

        # wait for the interceptor to find the snapshots view id, this means waiting until interceptor changes states from START_OK_FIND_SNAPSHOT to SNAPSHOT_OK_FIND_DEFECT_VIEW
        with self.interceptor_condition:
            while self.metadata_state != MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW:
                self.interceptor_condition.wait(self.interceptor_timeout)
                # timeout reached, panic exit
                if self.metadata_state != MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW:
                    logger.critical(f"Timeout reached while waiting got interceptor. Expected {MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW.name}, got {self.metadata_state.name}")
                    raise InterceptorTimeout()

        # now we are in SNAPSHOT_OK_FIND_DEFECT_VIEW state which means that we need defects view id using the snapshots view id
        

        # wait until we can double click on the most recent snapshot (double click on the first row, on the snapshot id)
        first_snapshot_id_cell = WebDriverWait(browser, 40).\
                until(EC.element_to_be_clickable(
                    (By.XPATH, "/html/body/cim-root/cim-shell/div/cim-project-view/div[1]/div[1]/div[1]/cim-data-table/angular-slickgrid/div/div/div[4]/div[3]/div/div[1]/div[1]")))
                
        trigger_recent_snapshot = ActionChains(self.browser)

        trigger_recent_snapshot.double_click(first_snapshot_id_cell).perform()

        # wait until we get both the defects view id and the defects from the last uploaded snapshot
        with self.interceptor_condition:
            while self.metadata_state != MetadataStates.DEFECT_OK_STOP:
                self.interceptor_condition.wait(self.interceptor_timeout)
                # timeout reached, panic exit
                if self.metadata_state != MetadataStates.DEFECT_OK_STOP:
                    logger.critical(f"Timeout reached while waiting got interceptor. Expected {MetadataStates.SNAPSHOT_OK_FIND_DEFECT_VIEW.name}, got {self.metadata_state.name}")
                    raise InterceptorTimeout()

        # close the defects window spawned by clicking the "View Defects" button
        browser.close()

        return self.cached_last_defect_results
    
    def prepare_defects_for_db(self, defect : dict) -> dict:

        # just remove the / from the beggining of the path, Coverity adds its since the archive submited is considered to be the whole filesystem

        defect['displayFile'] = defect['displayFile'][1 : ]

        return defect
    
    def check_recent_snapshot(self, compilation_tag : str):

        browser = self.browser
        
        # try to intercept response body which contains all snapshot information
        browser.response_interceptor = recent_snapshot_response_interceptor
        self.recent_snapshot_state = RecentSnapshotStates.STARTED_BUT_NOT_FOUND

        browser.switch_to.new_window('tab')
        
        browser.get(self.snapshots_url)

        # wait until the interceptor finds the response that contains the snapshot details
        with self.interceptor_condition:
            while self.recent_snapshot_state != RecentSnapshotStates.FOUND:
                self.interceptor_condition.wait(self.interceptor_timeout)

    def submit_build(self, app_path : str, compile_cmd : str, pipeline : bool) -> bool:
        
        upload_script_path = os.getcwd() + "/.."

        # make this env vars in order to pass them to the upload.sh script
        os.environ['UK_COV_APP_COMPILE_CMD'] = compile_cmd
        os.environ['UK_COV_APP_PATH'] = app_path

        job = f"{upload_script_path}/upload.sh"

        # pipeline means that the environment does not have the coverity build tools, so we need to download them beforehand
        if pipeline == True:
            os.environ['UK_COV_MODE'] = "--pipeline"

        # this is for running this tool on a development environment where the Coverity build tools exist
        else:
            os.environ['UK_COV_MODE'] = "--local"

        submit_proc = subprocess.Popen(job, shell=True, stdout=subprocess.PIPE, env=os.environ)

        out, err = submit_proc.communicate()
        
        submit_proc.terminate()

        if err != "" or err != None:
            return False
        
        logger.info(out)

        logger.warning(err)

        return True
                    
